{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding up numerical Python code\n",
    "\n",
    "### A guide with astromical examples\n",
    "by Bjoern Soergel, Institute of Astronomy, Cambridge, UK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: General ways of making Python code run parallel\n",
    "\n",
    "by Bjoern Soergel, Institute of Astronomy, Cambridge, UK \n",
    "\n",
    "\n",
    "### Background:\n",
    "\n",
    "CPython (the standard Python implementation written in C that we all use) has a feature called the *Global Interpreter Lock* (GIL). In a nutshell it means that *only one Python thread can execute bytecode at a time* (because the memory management is *not* thread-safe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\">>> import that\"\n",
    "\n",
    "The Unwritten Rules of Python\n",
    "\n",
    "1. You do not talk about the GIL.\n",
    "2. You do NOT talk about the GIL.\n",
    "3. Don't even mention the GIL. No seriously.\n",
    "\n",
    "(C) David Beazley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are two ways of parallelizing code in Python.\n",
    "\n",
    "We'll show examples for both of them. In both cases, we'll look at *embarassingly parallel* problems, i.e. cases where we can split up the computation in completely separate tasks that do not depend on each other.\n",
    "\n",
    "#### 1) Multi-threading (shared memory)\n",
    "\n",
    "This is best suited for I/O-limited problems, as it does not release the GIL. Therefore it does not provide any speed-up for CPU-bound problems.\n",
    "\n",
    "#### 2) Multi-processing (separate memory)\n",
    "\n",
    "If we want to execute CPU-limited code in parallel, we need to circumvent the GIL (as in the Cython parallel example above). Even without Cython, the multiprocessing module provides a way of doing this.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Python 1: Multi-threading:\n",
    "\n",
    "Let's begin with a simple example (partially based on http://roman-kh.github.io/numba-2/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04\n",
      "5\n",
      "\n",
      "16\n",
      "\n",
      "27\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "from math import ceil\n",
    "\n",
    "def testfunc_threading(x,S,N,res):\n",
    "    \"\"\"\n",
    "    all threads work on the same x and write to the same res, but all on different chunks\n",
    "    \"\"\"\n",
    "    for i in range(S,min(S+N, len(x))):\n",
    "        print(x[i])\n",
    "        res[i] = x[i]**2\n",
    "\n",
    "# number of threads\n",
    "T = 2\n",
    "# data size\n",
    "N = 8\n",
    "# data\n",
    "x = np.arange(N)\n",
    "# array for results\n",
    "r = np.zeros(N,dtype=int)\n",
    "\n",
    "# data size for each thread\n",
    "chunk_N = ceil(float(N)/T)\n",
    "# starting index for each thread\n",
    "chunks = [i * chunk_N for i in range(T)]\n",
    "\n",
    "#create threads\n",
    "threads = [threading.Thread(target=testfunc_threading, args=(x,chunks[i],chunk_N,r)) for i in range(T)]  \n",
    "#start them\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "#wait for them to finish\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  9, 16, 25, 36, 49])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this on a larger example to show that we are not making anything faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testfunc_threading2(x,S,N,res):\n",
    "    for i in range(S,min(S+N, len(x))):\n",
    "        res[i] = x[i]**2\n",
    "        \n",
    "# number of threads\n",
    "T = 2\n",
    "# data size\n",
    "N = int(1e7)\n",
    "# data\n",
    "x = np.arange(N)\n",
    "# array for results\n",
    "r = np.zeros(N,dtype=int)\n",
    "# data size for each thread\n",
    "chunk_N = ceil(float(N)/T)\n",
    "# starting index for each thread\n",
    "chunks = [i * chunk_N for i in range(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.5 s, sys: 35 ms, total: 5.53 s\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create threads\n",
    "threads = [threading.Thread(target=testfunc_threading2, args=(x,chunks[i],chunk_N,r)) for i in range(T)]  \n",
    "#start them\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "#wait for them to finish\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU time and Wall time are identical, indicating that we have not made anything faster.\n",
    "\n",
    "A few things worth noting:\n",
    "- If the task is I/O bound instead of CPU bound, there can indeed be a speed-up.\n",
    "- If we can release the GIL when calling the worker function, it is possible to run true multi-threaded code. Both numba and Cython allow this. For Cython, see our previous exercise. For numba, see e.g. http://roman-kh.github.io/numba-2/\n",
    "- There is an easier interface to *multithreading* that works exactly like the *multiprocessing* we show below, e.g. here http://chriskiehl.com/article/parallelism-in-one-line/  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Python 2: Multiprocessing\n",
    "\n",
    "Python's *multiprocessing* module spawns multiple subprocesses. All the data required by the subprocesses is serialized ('pickled') and passed to the individual subprocesses. Every subprocess works on their task independently, thus circumventing the GIL.\n",
    "\n",
    "For easy problems this is by far the quickest way of making your code parallel. But in comes with a few disadvantages:\n",
    "- Everything needs to be serialized. In some cases (e.g. class instances) this can be a problem.\n",
    "- Every subprocess has its own memory and needs a copy of all required data in it. This can lead to excessive memory requirements. Therefore: *Don't just blindly use Pool.map(), especially on shared systems like the IoA clusters!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "7\n",
      "[0, 1, 4, 9, 16, 25, 36, 49]\n"
     ]
    }
   ],
   "source": [
    "#this is now actual multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def testfunc(a):\n",
    "    print(a)\n",
    "    return a*a\n",
    "\n",
    "#create a pool of 4 subprocesses\n",
    "p = Pool(4)\n",
    "#sends task to subprocesses\n",
    "res = p.map(testfunc, np.arange(8))\n",
    "#clean-up\n",
    "p.close()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit the example from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5000000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testfunc_mp2(x):\n",
    "    \"\"\"\n",
    "    same computation but different I/O\n",
    "    \"\"\"\n",
    "    res = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        res[i] = x[i]**2\n",
    "    return res\n",
    "\n",
    "def split(a, n):\n",
    "    \"\"\"\n",
    "    split array or list along first dimension, into roughly equal sizes\n",
    "    \"\"\"\n",
    "    k, m = divmod(len(a), n)\n",
    "    splitlist = [ a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n) ] \n",
    "    return splitlist\n",
    "\n",
    "# number of threads\n",
    "T = 2\n",
    "# data size\n",
    "N = int(1e7)\n",
    "# data\n",
    "x = np.arange(N)\n",
    "x_split = split(x,T)\n",
    "# array for results\n",
    "len(x_split),x_split[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 79 ms, sys: 62 ms, total: 141 ms\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Note the elegant interface!\n",
    "pool = Pool(T) \n",
    "results = pool.map(testfunc_mp2, x_split)\n",
    "pool.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is around 2 times faster than the multi-threaded version. Now we are actually running in parallel!\n",
    "\n",
    "(NB: The CPU timings are a bit useless here because apparently sub-processes are not counted.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's apply the same to our naive Python implementation of the contaminant removal problem.\n",
    "\n",
    "*NB: This is not the easiest example to apply multi-processing to, because (unlike the simple example above) we are interested in the indices of the objects.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3) (500, 3)\n"
     ]
    }
   ],
   "source": [
    "#same as in other notebook\n",
    "def angdistcut_python_naive(vec_obj,vec_ps,cos_maxsep):\n",
    "    nobj = vec_obj.shape[0]\n",
    "    nps = vec_ps.shape[0]\n",
    "    dim = vec_obj.shape[1]\n",
    "    #objects to be deleted\n",
    "    out = []\n",
    "    for i in range(nobj):\n",
    "        for j in range(nps):\n",
    "            cos = 0.\n",
    "            #compute dot product\n",
    "            for k in range(dim):\n",
    "                cos += vec_obj[i,k] * vec_ps[j,k]\n",
    "            #stop once we have found one contaminant\n",
    "            if cos > cos_maxsep:\n",
    "                out.append(i)\n",
    "                break   \n",
    "    return np.array(out)\n",
    "\n",
    "#helper function to generate points\n",
    "def gen_points_sphere(n):\n",
    "    \"\"\"\n",
    "    generate random points on sphere\n",
    "    \"\"\"\n",
    "    #angles\n",
    "    costheta = 2*np.random.rand(n)-1\n",
    "    theta = np.arccos(costheta)\n",
    "    phi = 2*np.pi*np.random.rand(n)\n",
    "    #unit vectors on the sphere\n",
    "    x = np.sin(theta)*np.cos(phi)\n",
    "    y = np.sin(theta)*np.sin(phi)\n",
    "    z = np.cos(theta)\n",
    "    vec = np.array([x,y,z]).T\n",
    "    return vec,theta,phi\n",
    "\n",
    "#generate populations for example\n",
    "# objects (obj)\n",
    "vec_obj,theta_obj,phi_obj = gen_points_sphere(5000) # ~500,000 in my real use case\n",
    "# contaminants (ps)\n",
    "vec_ps,theta_ps,phi_ps = gen_points_sphere(500) # ~50,000 in my real use case\n",
    "print(vec_obj.shape,vec_ps.shape)\n",
    "# maximum separation: \n",
    "maxsep_deg = 1.\n",
    "cos_maxsep = np.cos(np.deg2rad(maxsep_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 3), 2, (2500, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Every process needs the full list of contaminants. \n",
    "#The easiest way to get this is to create a new function where these fixed arguments are already filled in.\n",
    "from functools import partial\n",
    "angdistcut_python_partial = partial(angdistcut_python_naive,vec_ps=vec_ps,cos_maxsep=cos_maxsep)\n",
    "\n",
    "#split vec_obj array along first dimension into roughly equal sized chunks\n",
    "ncores = 2\n",
    "vec_obj_split = split(vec_obj,ncores)\n",
    "vec_obj.shape,len(vec_obj_split),vec_obj_split[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ms, sys: 7 ms, total: 10 ms\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = Pool(ncores)\n",
    "#sends task to subprocesses\n",
    "reslist = p.map(angdistcut_python_partial, vec_obj_split)\n",
    "#clean-up\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bring results in the correct format again\n",
    "counter = 0\n",
    "result_python_mp = []\n",
    "#make sure we get the original indices again\n",
    "for res,s in zip(reslist,vec_obj_split):\n",
    "    result_python_mp.append(np.array(res)+counter)\n",
    "    counter += len(s)\n",
    "result_python_mp = np.array([item for sublist in result_python_mp for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.85 s, sys: 0 ns, total: 2.85 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_python_naive = angdistcut_python_partial(vec_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert np.array_equal(result_python_mp,result_python_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is some overhead associated with serializing and creating the subprocesses, we get only a factor 1.5 speedup on 2 cores. For larger computations, the impact of the overhead is smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
